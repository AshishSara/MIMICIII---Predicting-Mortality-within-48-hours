{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "For our objective, it's particularly important to focus not just on overall accuracy but also on the model's ability to correctly identify the high-risk patients (Class 1). This is why metrics like recall, precision, ROC AUC, and F1-score for the mortality class are essential.\n",
    "\n",
    "Model Interpretation: For some of the more elementary models we performed feature importance analysis,to provide us insights into which factors are most predictive of near-term mortality, helping clinicians understand key risk factors.\n",
    "\n",
    "Use in Clinical Settings: Such models, if deployed in clinical settings, can assist healthcare professionals in making informed decisions, but they should be used as a supplement to, not a replacement for, clinical judgment and expertise.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eea8824ddeb675b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the features and labels for the specific task (in-hospital mortality at 48 hours). This will involve importing necessary packages and reading the data files."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5294943113e495ea"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T02:37:31.727720Z",
     "start_time": "2023-11-23T02:37:27.056653Z"
    }
   },
   "outputs": [],
   "source": [
    "import sparse\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Replace {task} with the specific task, e.g., 'mortality_48h'\n",
    "s = sparse.load_npz('Features/s.npz').todense()\n",
    "X = sparse.load_npz('Features/X.npz').todense()\n",
    "\n",
    "s_feature_names = json.load(open('Features/s.feature_names.json', 'r'))\n",
    "X_feature_names = json.load(open('Features/X.feature_names.json', 'r'))\n",
    "\n",
    "df_pop = pd.read_csv('Population/mortality_48h.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Why I decided to combine the time-invariant and time-dependent features for this file\n",
    "\n",
    "Holistic View of Data: Combining both time-invariant and time-dependent features provides a more comprehensive view of each patient's record. Time-invariant data often includes critical baseline information, while time-dependent data captures dynamic changes. Using both together allows the model to make more informed predictions.\n",
    "\n",
    "Model Limitations: Most traditional machine learning models, including Random Forest, expect input data in a tabular format (2D). They are not designed to natively handle 3D tensors (such as those including time steps as a separate dimension). Therefore, reshaping and combining the data into a 2D format makes it compatible with these models.\n",
    "\n",
    "Feature Relationships: By combining the features, you allow the model to learn from both static patient characteristics and their changes over time, potentially uncovering important relationships between these features.\n",
    "\n",
    "Simplifies Model Training: Having a single dataset simplifies the model training process. It allows you to feed all relevant information into the model at once, rather than trying to integrate separate models for time-invariant and time-dependent data.\n",
    "\n",
    "Practicality in Model Evaluation and Deployment: With a single model that considers all features, it's easier to evaluate its performance, tune it, and potentially deploy it in a real-world setting.\n",
    "\n",
    "Caveats\n",
    "Dimensionality: The trade-off is that combining features can lead to high dimensionality, as you've experienced. This requires careful handling to ensure the model isn't overwhelmed by too many features, some of which might be noisy or irrelevant.\n",
    "Feature Importance Interpretation: When time-dependent features are expanded across time steps, interpreting the model's feature importance can become more complex.\n",
    "Alternative Approaches\n",
    "In some cases, alternative modeling approaches that can natively handle time-series data, like Recurrent Neural Networks (RNNs) or Long Short-Term Memory (LSTM) networks, might be used. However, these models are more complex and computationally intensive compared to Random Forest."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f00f65770f2f6014"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of time-invariant features (s): (8577, 96)\n",
      "Shape of time-dependent features (X) after reshaping: (8577, 350736)\n",
      "Shape of combined features: (8577, 350832)\n",
      "Total number of features in combined dataset: 350832\n",
      "Total number of feature names: 350832\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Reshape X from 3D tensor to 2D matrix\n",
    "# The new shape should be (number of patients, time * features)\n",
    "# Assuming the first dimension of X is the number of patients\n",
    "num_patients = X.shape[0]\n",
    "time_steps = X.shape[1]\n",
    "num_features_X = X.shape[2]\n",
    "\n",
    "X_reshaped = X.reshape(num_patients, time_steps * num_features_X)\n",
    "\n",
    "# Concatenate s (time-invariant) and X_reshaped (time-dependent) features\n",
    "# Ensure that both s and X_reshaped have the same number of rows (patients)\n",
    "combined_features = np.concatenate([s, X_reshaped], axis=1)\n",
    "\n",
    "# Now combined_features is your full feature set for the model\n",
    "print(f\"Shape of time-invariant features (s): {s.shape}\")\n",
    "print(f\"Shape of time-dependent features (X) after reshaping: {X_reshaped.shape}\")\n",
    "print(f\"Shape of combined features: {combined_features.shape}\")\n",
    "\n",
    "# Expanding time-dependent feature names for each time step\n",
    "expanded_X_feature_names = [f\"{name}_time{t}\" for t in range(time_steps) for name in X_feature_names]\n",
    "\n",
    "# Combine with time-invariant feature names\n",
    "total_feature_names = s_feature_names + expanded_X_feature_names\n",
    "\n",
    "# Check if the numbers match now\n",
    "print(f\"Total number of features in combined dataset: {combined_features.shape[1]}\")\n",
    "print(f\"Total number of feature names: {len(total_feature_names)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:07:08.713599Z",
     "start_time": "2023-11-23T03:06:58.985393Z"
    }
   },
   "id": "d8df3a55c10f9aa5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the contents of the mortality_48h.csv file provided. The partition column categorizes each record into different sets: typically 'train', 'test', and sometimes 'validation'."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26b8e57c5c94cebd"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# 'combined_features' is combined dataset from time-invariant and time-dependent data\n",
    "\n",
    "# Separating data based on the predefined splits\n",
    "train_data = combined_features[df_pop['partition'] == 'train']\n",
    "test_data = combined_features[df_pop['partition'] == 'test']\n",
    "# If there's a validation set\n",
    "# validation_data = combined_features[df_population['partition'] == 'validation']\n",
    "\n",
    "# Separating labels\n",
    "train_labels = df_pop[df_pop['partition'] == 'train']['mortality_LABEL']\n",
    "test_labels = df_pop[df_pop['partition'] == 'test']['mortality_LABEL']\n",
    "validation_labels = df_pop[df_pop['partition'] == 'val']['mortality_LABEL']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:09:59.752090Z",
     "start_time": "2023-11-23T03:09:51.243721Z"
    }
   },
   "id": "cfafc8a9dbec91f6"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# After loading and combining features and labels\n",
    "\n",
    "# Check 1: Ensure matching indices between df_pop and combined_features\n",
    "if len(df_pop) != combined_features.shape[0]:\n",
    "    raise ValueError(\"Mismatch in number of rows between df_pop and combined features\")\n",
    "\n",
    "# Check 2: Check the dimensions of split data\n",
    "if train_data.shape[0] != train_labels.shape[0]:\n",
    "    raise ValueError(\"Mismatch in number of rows between train_data and train_labels\")\n",
    "\n",
    "if test_data.shape[0] != test_labels.shape[0]:\n",
    "    raise ValueError(\"Mismatch in number of rows between test_data and test_labels\")\n",
    "\n",
    "# If you have a validation set\n",
    "if validation_labels.shape[0] != df_pop[df_pop['partition'] == 'val'].shape[0]:\n",
    "    raise ValueError(\"Mismatch in number of rows between validation_data and validation_labels\")\n",
    "\n",
    "# Check 3: Verify feature concatenation\n",
    "expected_feature_count = s.shape[1] + X_reshaped.shape[1]\n",
    "if combined_features.shape[1] != expected_feature_count:\n",
    "    raise ValueError(\"Mismatch in number of features after concatenation\")\n",
    "\n",
    "# Check 4: Check for NaNs or infinite values\n",
    "if np.isnan(combined_features).any() or np.isinf(combined_features).any():\n",
    "    raise ValueError(\"NaNs or infinite values found in combined features\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:10:04.929925Z",
     "start_time": "2023-11-23T03:10:03.666147Z"
    }
   },
   "id": "58deba5f33ba48b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the nature of MIMIC III dataset, which is derived from large-scale electronic health record (EHR) databases and involves high-dimensional feature representations, selecting the right machine learning model is key. The choice of model should balance the ability to handle complex, high-dimensional data with interpretability and computational efficiency.\n",
    "\n",
    "Theoretically Favourable Models\n",
    "Random Forest: This model is excellent for handling high-dimensional data and does not require scaling of features. It's also good for interpretation as it can provide feature importance.\n",
    "\n",
    "Gradient Boosting Machines (GBM): Models like XGBoost or LightGBM are powerful for high-dimensional data and often provide better performance than Random Forest, though they might be less interpretable and require careful tuning.\n",
    "\n",
    "*Neural Networks: Deep learning models can be very effective for complex datasets but require more computational resources. They might be overkill for this task unless I specifically need to model non-linear, complex relationships and interactions in the data. In addition, for neural networks they work with data where the time-dependent and time invariant features are independent instead of combined as shown here. Hence, we will explore them in another notebook.*\n",
    "\n",
    "Logistic Regression with Regularization: If interpretability is a key concern, logistic regression with L1 or L2 regularization can be a good choice. It's simpler than tree-based models but can still handle high-dimensional data with the right regularization.\n",
    "\n",
    "Support Vector Machines (SVM): SVM with a linear or non-linear kernel can be effective, especially if the dataset has clear margins of separation. However, they can be computationally intensive for very large datasets.\n",
    "\n",
    "Model Evaluation\n",
    "Cross-Validation: Use cross-validation to assess the generalizability of your model.\n",
    "Metrics: Given this is a healthcare dataset, metrics like accuracy, precision, recall, F1 score, and especially the Area Under the ROC Curve (AUC-ROC) are important."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dd68d657726f6c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Random Forest**\n",
    "\n",
    "Code Description\n",
    "n_estimators: This parameter specifies the number of trees in the forest. You can experiment with different values, but 100 is a good starting point.\n",
    "random_state: Setting a random state ensures reproducibility.\n",
    "Model Evaluation: The code includes accuracy and ROC AUC metrics, which are standard for classification tasks. The classification report provides a detailed breakdown of precision, recall, and F1-score for each class. ROC AUC, is especially important in binary classification tasks, especially in medical contexts where the balance between sensitivity (true positive rate) and specificity (true negative rate) is important. A value closer to 1 indicates a better model\n",
    "Feature Importance: Random Forest can provide insights into which features are most important for the prediction. You can access this using random_forest_model.feature_importances_."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "746bf16b36d297b8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8955696202531646\n",
      "ROC AUC: 0.5133847306992183\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      1132\n",
      "           1       0.50      0.03      0.06       132\n",
      "\n",
      "    accuracy                           0.90      1264\n",
      "   macro avg       0.70      0.51      0.50      1264\n",
      "weighted avg       0.86      0.90      0.85      1264\n",
      "\n",
      "Top Feature rankings:\n",
      "1. Feature: 226104_value_Unresponsive_time46, Importance: 0.0017349550073114859\n",
      "2. Feature: 225154_InputRoute: Continuous Med_value_1.0_time46, Importance: 0.0013277409871644932\n",
      "3. Feature: 225792_value_1.0_time46, Importance: 0.000993736674619391\n",
      "4. Feature: 225154_InputRoute: Continuous Med_value_1.0_time47, Importance: 0.0009186840100308196\n",
      "5. Feature: 225792_value_1.0_time34, Importance: 0.0008215305539938766\n",
      "6. Feature: 221906_value_1.0_time37, Importance: 0.0008183066326337454\n",
      "7. Feature: 223904_value_Absent_time30, Importance: 0.000745496294177183\n",
      "8. Feature: 221906_Rate_value_(0.0262, 9.356]_time42, Importance: 0.0007307279700927923\n",
      "9. Feature: 220739_value_None_time46, Importance: 0.0007251080206447534\n",
      "10. Feature: 225792_value_1.0_time37, Importance: 0.0007247672172312946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# Assuming train_data, train_labels, test_data, test_labels are already defined\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "random_forest_model.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the test data\n",
    "test_predictions = random_forest_model.predict(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "roc_auc = roc_auc_score(test_labels, test_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Feature Importance Analysis\n",
    "importances = random_forest_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Top Feature rankings:\")\n",
    "for i in range(10):  # Top 10 features; adjust as needed\n",
    "    print(f\"{i + 1}. Feature: {total_feature_names[indices[i]]}, Importance: {importances[indices[i]]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:11:58.426785Z",
     "start_time": "2023-11-23T03:10:23.463224Z"
    }
   },
   "id": "f4e2acbc7e573480"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Understanding the Feature Names**\n",
    "Feature Identifier (e.g., 226104, 225154): These numbers likely correspond to specific measurements, observations, or interventions recorded in the electronic health records. For example, they could be codes for certain lab tests, vital signs, medication administrations, or other clinical data points.\n",
    "\n",
    "Feature Description (e.g., value, InputRoute): This part describes the nature of the feature. For example, value might indicate the recorded value of a measurement, while InputRoute could specify the route of medication administration (like oral, intravenous, etc.).\n",
    "\n",
    "Feature Value (e.g., Unresponsive, 1.0, Absent): This represents the actual value or category of the feature. For instance, Unresponsive might indicate the patient's response status, 1.0 could be a binary indicator (such as presence/absence of a condition or response), and Absent might refer to the absence of a certain clinical sign.\n",
    "\n",
    "Time Point (e.g., time46): This indicates the specific time step in the patient's data timeline. For time-dependent features, each time step (e.g., hour, day) is treated as a separate feature. time46 means the feature's value at the 46th time step (the exact unit depends on how the data was recorded and processed).\n",
    "\n",
    "Understanding in Context\n",
    "To fully understand these features, you would need to refer to the documentation of the MIMIC-III and eICU databases or consult with healthcare professionals familiar with these datasets. They can provide the context behind these identifiers and what each feature represents in a clinical setting.\n",
    "\n",
    "For example, a feature like 226104_value_Unresponsive_time46 might be interpreted as the patient's response status (Unresponsive) recorded at the 46th time step in the dataset.\n",
    "\n",
    "The feature 225154_InputRoute: Continuous Med_value_1.0_time46 could indicate that at the 46th time step, there was a continuous medication administered (value 1.0 meaning 'Yes' or 'Present')."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "969c7d2d3cfb5568"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Gradient Boosting**\n",
    "\n",
    "Hyperparameter Selection:\n",
    "n_estimators (Number of Trees):\n",
    "\n",
    "Initial Value: 100\n",
    "Rationale: A larger number of trees can improve the model's ability to capture complex patterns, but also increases the risk of overfitting, especially in a high-dimensional space. Starting with 100 is a balanced choice, allowing us to observe model performance without excessive computational demand.\n",
    "Adjustment Consideration: If the model underfits, you may increase this number. If it overfits, decreasing it or adding regularization might help.\n",
    "learning_rate (Shrinkage):\n",
    "\n",
    "Initial Value: 0.1\n",
    "Rationale: This controls the contribution of each tree to the final model. A lower rate requires more trees but can lead to a more robust model. 0.1 is a common starting point that balances model complexity and training efficiency.\n",
    "Adjustment Consideration: If the model trains too slowly or overfits, you might increase this rate. If it underfits, decreasing the rate could help.\n",
    "max_depth (Depth of Each Tree):\n",
    "\n",
    "Initial Value: 5\n",
    "Rationale: Given the high dimensionality, a certain level of depth is required to capture interactions between features. However, too much depth can lead to overfitting. A moderate depth like 5 is a starting point that allows for some complexity without being too prone to overfitting.\n",
    "Adjustment Consideration: If the model underfits, you can increase the depth. If it overfits, reducing the depth or increasing regularization may be beneficial.\n",
    "\n",
    "\n",
    "Feature Importance: XGBoost also provides feature importance, which can be useful for understanding the predictive drivers in your dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9ddc17a8b81c2e"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9098101265822784\n",
      "ROC AUC: 0.6317592890031052\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1132\n",
      "           1       0.66      0.28      0.39       132\n",
      "\n",
      "    accuracy                           0.91      1264\n",
      "   macro avg       0.79      0.63      0.67      1264\n",
      "weighted avg       0.89      0.91      0.89      1264\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "xgb_model.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the test data\n",
    "xgb_predictions = xgb_model.predict(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, xgb_predictions)\n",
    "roc_auc = roc_auc_score(test_labels, xgb_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, xgb_predictions))\n",
    "\n",
    "# Feature Importance Analysis (optional)\n",
    "xgb_importances = xgb_model.feature_importances_\n",
    "# You can use similar logic as before to display feature importances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:27:17.026859Z",
     "start_time": "2023-11-23T03:23:13.406625Z"
    }
   },
   "id": "c7d10f511e939b75"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Feature rankings:\n",
      "1. Feature: 225792_value_1.0_time47, Importance: 0.020830070599913597\n",
      "2. Feature: 225792_value_1.0_time46, Importance: 0.012420390732586384\n",
      "3. Feature: 225154_InputRoute: Continuous Med_value_1.0_time47, Importance: 0.008466214872896671\n",
      "4. Feature: 225158_value_1.0_time47, Importance: 0.005562117788940668\n",
      "5. Feature: 226559_value_(-0.001, 30.0]_time40, Importance: 0.005055662710219622\n",
      "6. Feature: 225158_InputRoute: Continuous Med_value_1.0_time42, Importance: 0.005000233184546232\n",
      "7. Feature: 226104_value_Unresponsive_time46, Importance: 0.004466429818421602\n",
      "8. Feature: 225158_value_1.0_time42, Importance: 0.004417689982801676\n",
      "9. Feature: 221906_value_1.0_time47, Importance: 0.0038532603066414595\n",
      "10. Feature: 221906_value_1.0_time34, Importance: 0.0036179297603666782\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances from the trained XGBoost model\n",
    "xgb_importances = xgb_model.feature_importances_\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "indices = np.argsort(xgb_importances)[::-1]\n",
    "\n",
    "# Display the top 10 feature importances\n",
    "print(\"Top Feature rankings:\")\n",
    "for i in range(10):  # Adjust the range as needed to display more or fewer features\n",
    "    feature_name = total_feature_names[indices[i]] if indices[i] < len(total_feature_names) else \"Feature Index Out of Bound\"\n",
    "    print(f\"{i + 1}. Feature: {feature_name}, Importance: {xgb_importances[indices[i]]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:33:45.160341Z",
     "start_time": "2023-11-23T03:33:45.063313Z"
    }
   },
   "id": "764c754d5f2f254b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpretation of the Results\n",
    "Time-Dependent Features: Similar to the Random Forest model, the XGBoost model also emphasizes the importance of time-dependent features. This suggests that certain conditions or observations at specific time points are critical in determining the outcome.\n",
    "\n",
    "Feature Specifics: The features identified (e.g., 225792_value_1.0_time47, 226104_value_Unresponsive_time46) correspond to specific measurements, statuses, or interventions recorded in the EHR data. Their significance might reflect clinical conditions or treatments that are particularly relevant to patient outcomes at those times.\n",
    "\n",
    "Clinical Relevance: Each feature likely has a clinical interpretation. For instance, 225792_value_1.0_time47 might indicate a particular measurement or status that is crucial at the 47th time step. The importance of Unresponsive status at a certain time point could be indicative of critical patient conditions.\n",
    "\n",
    "Value Ranges: Some features include value ranges (e.g., (-0.001, 30.0]), which might represent discretized or binned values of continuous variables."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e13c90d35961efdc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Logistic Regression with L1 Regularization (Lasso)**\n",
    "L1 regularization tends to push coefficients of less important features to exactly zero, thus performing feature selection.\n",
    "\n",
    "\n",
    "\n",
    "Considerations:\n",
    "Regularization Strength: The C parameter in LogisticRegression controls the strength of regularization. Lower values of C specify stronger regularization. You might need to experiment with this parameter to find the best value.\n",
    "\n",
    "Solver: The choice of solver is important especially for large datasets. For L1 regularization, liblinear is a good choice. For L2, you might also consider lbfgs or sag for larger datasets.\n",
    "\n",
    "Max Iterations (max_iter): Depending on your dataset's size and complexity, you might need to increase the number of iterations.\n",
    "\n",
    "Scaling Features: Logistic Regression can benefit from feature scaling, especially if regularization is used.\n",
    "\n",
    "Interpretability: After training, you can examine the coefficients of the model to understand the influence of each feature. Features with larger absolute coefficients are more influential in predicting the outcome."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8916bb9803183f85"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (L1): 0.8916139240506329\n",
      "ROC AUC (L1): 0.6584082878252491\n",
      "Classification Report (L1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1132\n",
      "           1       0.48      0.36      0.41       132\n",
      "\n",
      "    accuracy                           0.89      1264\n",
      "   macro avg       0.70      0.66      0.68      1264\n",
      "weighted avg       0.88      0.89      0.89      1264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# Initialize the Logistic Regression model with L1 regularization\n",
    "log_reg_l1 = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=100)\n",
    "\n",
    "# Train the model\n",
    "log_reg_l1.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the test data\n",
    "log_reg_l1_predictions = log_reg_l1.predict(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_l1 = accuracy_score(test_labels, log_reg_l1_predictions)\n",
    "roc_auc_l1 = roc_auc_score(test_labels, log_reg_l1_predictions)\n",
    "\n",
    "print(f\"Accuracy (L1): {accuracy_l1}\")\n",
    "print(f\"ROC AUC (L1): {roc_auc_l1}\")\n",
    "print(\"Classification Report (L1):\")\n",
    "print(classification_report(test_labels, log_reg_l1_predictions))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:39:02.412455Z",
     "start_time": "2023-11-23T03:38:49.988627Z"
    }
   },
   "id": "c86c4aaeaff510d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Logistic Regression with L2 Regularization (Ridge)**\n",
    "L2 regularization tends to shrink the coefficients of less important features, but does not set them to zero."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63c508282168a81"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (L2): 0.8884493670886076\n",
      "ROC AUC (L2): 0.6198334939501017\n",
      "Classification Report (L2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1132\n",
      "           1       0.45      0.28      0.34       132\n",
      "\n",
      "    accuracy                           0.89      1264\n",
      "   macro avg       0.68      0.62      0.64      1264\n",
      "weighted avg       0.87      0.89      0.88      1264\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model with L2 regularization\n",
    "log_reg_l2 = LogisticRegression(penalty='l2', solver='liblinear', random_state=42, max_iter=100)\n",
    "\n",
    "# Train the model\n",
    "log_reg_l2.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the test data\n",
    "log_reg_l2_predictions = log_reg_l2.predict(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_l2 = accuracy_score(test_labels, log_reg_l2_predictions)\n",
    "roc_auc_l2 = roc_auc_score(test_labels, log_reg_l2_predictions)\n",
    "\n",
    "print(f\"Accuracy (L2): {accuracy_l2}\")\n",
    "print(f\"ROC AUC (L2): {roc_auc_l2}\")\n",
    "print(\"Classification Report (L2):\")\n",
    "print(classification_report(test_labels, log_reg_l2_predictions))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:41:34.757162Z",
     "start_time": "2023-11-23T03:41:04.572345Z"
    }
   },
   "id": "d94ae6f498a44c4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**SVM**\n",
    "Considerations\n",
    "Calibration of Probabilities: LinearSVC doesn't output probabilities by default, which are needed for ROC AUC. CalibratedClassifierCV is used to calibrate probabilities in a post-processing step.\n",
    "\n",
    "Maximum Iterations (max_iter): This parameter may need adjustment. Increase it if the algorithm doesn't converge, but be aware that higher values will increase computation time.\n",
    "\n",
    "Handling Large Datasets: Linear SVMs are generally more scalable for large datasets, but if you still face computational issues, consider using a subset of the data or feature selection techniques to reduce dimensionality.\n",
    "\n",
    "Non-linear SVM: If the linear SVM does not perform adequately, exploring non-linear kernels like RBF might be beneficial, though at a higher computational cost.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53104c2313e60797"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashishsaragadam/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/ashishsaragadam/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/ashishsaragadam/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/ashishsaragadam/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/ashishsaragadam/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9003164556962026\n",
      "ROC AUC: 0.8151434843130956\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      1132\n",
      "           1       0.57      0.18      0.28       132\n",
      "\n",
      "    accuracy                           0.90      1264\n",
      "   macro avg       0.74      0.58      0.61      1264\n",
      "weighted avg       0.88      0.90      0.88      1264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Initialize the Linear SVM model\n",
    "linear_svc = LinearSVC(random_state=42, max_iter=1000)\n",
    "\n",
    "# Calibrate probabilities\n",
    "svm_calibrated = CalibratedClassifierCV(linear_svc) \n",
    "\n",
    "# Train the model\n",
    "svm_calibrated.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the test data\n",
    "svm_predictions = svm_calibrated.predict(test_data)\n",
    "svm_probabilities = svm_calibrated.predict_proba(test_data)[:, 1]  # Probabilities for ROC AUC\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, svm_predictions)\n",
    "roc_auc = roc_auc_score(test_labels, svm_probabilities)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, svm_predictions))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:53:37.861986Z",
     "start_time": "2023-11-23T03:52:20.821292Z"
    }
   },
   "id": "ddda914623641420"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**RNN**\n",
    "\n",
    "So remember how we reshaped and combined the time-dependent (X) and time-invariant (s) features into a single 2D matrix (combined_features)? This format was suitable for models like Random Forest, XGBoost, and Logistic Regression.\n",
    "\n",
    "'# Reshape X from 3D tensor to 2D matrix\n",
    "# The new shape should be (number of patients, time * features)\n",
    "# Assuming the first dimension of X is the number of patients\n",
    "num_patients = X.shape[0]\n",
    "time_steps = X.shape[1]\n",
    "num_features_X = X.shape[2]\n",
    "\n",
    "X_reshaped = X.reshape(num_patients, time_steps * num_features_X)\n",
    "\n",
    "# Concatenate s (time-invariant) and X_reshaped (time-dependent) features\n",
    "# Ensure that both s and X_reshaped have the same number of rows (patients)\n",
    "combined_features = np.concatenate([s, X_reshaped], axis=1)'\n",
    "\n",
    "However, for an RNN, we need to maintain the time-dependent features in their original 3D tensor format and handle the time-invariant features differently, as RNNs are designed to process sequential data. Let's adjust the preparation of your data for the RNN model.\n",
    "\n",
    "Adjusting Data for RNN\n",
    "Revert to Original 3D Tensor for Time-Dependent Features: Need to use X in its original (num_patients, time_steps, num_features_X) format.\n",
    "\n",
    "Repeat Time-Invariant Features for Each Time Step: Repeat s for each time step and concatenate it with X along the feature dimension."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c71e3bb16a1d07"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of time-dependent features (X): (8577, 48, 7307)\n",
      "Shape of repeated time-invariant features (s): (8577, 48, 96)\n",
      "Shape of RNN input: (8577, 48, 7403)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X is your time-dependent data (3D tensor) and s is your time-invariant data (2D matrix)\n",
    "\n",
    "# Repeat time-invariant features (s) for each time step\n",
    "s_repeated = np.repeat(s[:, np.newaxis, :], time_steps, axis=1)\n",
    "\n",
    "# Concatenate with time-dependent features (X) along the feature dimension\n",
    "rnn_input = np.concatenate([X, s_repeated], axis=-1)\n",
    "\n",
    "# Now, 'rnn_input' is in the correct format for RNN input\n",
    "print(f\"Shape of time-dependent features (X): {X.shape}\")\n",
    "print(f\"Shape of repeated time-invariant features (s): {s_repeated.shape}\")\n",
    "print(f\"Shape of RNN input: {rnn_input.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:24:35.434801Z",
     "start_time": "2023-11-23T14:24:25.194354Z"
    }
   },
   "id": "774c51ee02e05a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "What does the output above mean?\n",
    "\n",
    "Time-Dependent Features (X): (8577, 48, 7307)\n",
    "\n",
    "You have 8,577 patients.\n",
    "Each patient has data recorded over 48 time steps.\n",
    "There are 7,307 features per time step.\n",
    "\n",
    "Repeated Time-Invariant Features (s): (8577, 48, 96)\n",
    "The 96 time-invariant features are repeated for each of the 48 time steps.\n",
    "\n",
    "Combined RNN Input: (8577, 48, 7403)\n",
    "Each patient's data is now a sequence of 48 time steps.\n",
    "At each time step, there are 7,403 features (7,307 time-dependent + 96 time-invariant)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b808363d07fcda01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Since the format of the data for the RNN is different from what we used for the other models, we need to adjust the way you partition the data into training, testing, and validation sets.\n",
    "\n",
    "For the RNN, we have the rnn_input tensor that combines both the time-dependent and time-invariant features appropriately. we need to split this tensor along with the labels according to the partitions indicated in df_pop."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "907879e87f8cb70f"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Create boolean masks for train, test, and validation partitions\n",
    "train_mask = df_pop['partition'] == 'train'\n",
    "test_mask = df_pop['partition'] == 'test'\n",
    "val_mask = df_pop['partition'] == 'val' \n",
    "\n",
    "# Split the rnn_input tensor and labels according to the partitions\n",
    "rnn_input_train = rnn_input[train_mask]\n",
    "rnn_input_test = rnn_input[test_mask]\n",
    "rnn_input_val = rnn_input[val_mask]  \n",
    "\n",
    "train_labels = df_pop[train_mask]['mortality_LABEL']\n",
    "test_labels = df_pop[test_mask]['mortality_LABEL']\n",
    "val_labels = df_pop[val_mask]['mortality_LABEL']  \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T04:13:14.220465Z",
     "start_time": "2023-11-23T04:13:10.247830Z"
    }
   },
   "id": "3fe5dd261e97bf5"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "189/189 [==============================] - 5s 24ms/step\n",
      "40/40 [==============================] - 1s 16ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 33\u001B[0m\n\u001B[1;32m     29\u001B[0m rocauc_callback \u001B[38;5;241m=\u001B[39m RocAucCallback(training_data\u001B[38;5;241m=\u001B[39m(rnn_input_train, train_labels),\n\u001B[1;32m     30\u001B[0m                                  validation_data\u001B[38;5;241m=\u001B[39m(rnn_input_val, val_labels))\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# Train the model with validation data and the custom callback\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(rnn_input_train, train_labels, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, \n\u001B[1;32m     34\u001B[0m           validation_data\u001B[38;5;241m=\u001B[39m(rnn_input_val, val_labels), callbacks\u001B[38;5;241m=\u001B[39m[rocauc_callback])\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# Evaluate the model on the test set\u001B[39;00m\n\u001B[1;32m     37\u001B[0m loss, accuracy \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(rnn_input_test, test_labels)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "Cell \u001B[0;32mIn[34], line 16\u001B[0m, in \u001B[0;36mRocAucCallback.on_epoch_end\u001B[0;34m(self, epoch, logs)\u001B[0m\n\u001B[1;32m     14\u001B[0m y_train_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpredict(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx_train)\n\u001B[1;32m     15\u001B[0m y_val_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpredict(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx_val)\n\u001B[0;32m---> 16\u001B[0m roc_auc_train \u001B[38;5;241m=\u001B[39m roc_auc_score(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_train, y_train_pred)\n\u001B[1;32m     17\u001B[0m roc_auc_val \u001B[38;5;241m=\u001B[39m roc_auc_score(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_val, y_val_pred)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: roc_auc_train: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mroc_auc_train\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, roc_auc_val: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mroc_auc_val\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    209\u001B[0m         )\n\u001B[1;32m    210\u001B[0m     ):\n\u001B[0;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    221\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:605\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[1;32m    603\u001B[0m y_type \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    604\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 605\u001B[0m y_score \u001B[38;5;241m=\u001B[39m check_array(y_score, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m    608\u001B[0m     y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m y_score\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m y_score\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m    609\u001B[0m ):\n\u001B[1;32m    610\u001B[0m     \u001B[38;5;66;03m# do not support partial ROC computation for multiclass\u001B[39;00m\n\u001B[1;32m    611\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_fpr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m max_fpr \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:953\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    948\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    949\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    950\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    951\u001B[0m     )\n\u001B[1;32m    952\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nd \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[0;32m--> 953\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    954\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    955\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    956\u001B[0m     )\n\u001B[1;32m    958\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m    959\u001B[0m     _assert_all_finite(\n\u001B[1;32m    960\u001B[0m         array,\n\u001B[1;32m    961\u001B[0m         input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[1;32m    962\u001B[0m         estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[1;32m    963\u001B[0m         allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    964\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Custom callback to compute ROC AUC after each epoch\n",
    "class RocAucCallback(Callback):\n",
    "    def __init__(self, training_data, validation_data):\n",
    "        self.x_train, self.y_train = training_data\n",
    "        self.x_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_train_pred = self.model.predict(self.x_train)\n",
    "        y_val_pred = self.model.predict(self.x_val)\n",
    "        roc_auc_train = roc_auc_score(self.y_train, y_train_pred)\n",
    "        roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
    "        print(f'Epoch {epoch+1}: roc_auc_train: {roc_auc_train}, roc_auc_val: {roc_auc_val}')\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, return_sequences=True, input_shape=(48, 7403)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Instantiate the RocAucCallback\n",
    "rocauc_callback = RocAucCallback(training_data=(rnn_input_train, train_labels),\n",
    "                                 validation_data=(rnn_input_val, val_labels))\n",
    "\n",
    "# Train the model with validation data and the custom callback\n",
    "model.fit(rnn_input_train, train_labels, epochs=10, batch_size=64, \n",
    "          validation_data=(rnn_input_val, val_labels), callbacks=[rocauc_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(rnn_input_test, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate and print ROC AUC for the test set\n",
    "test_predictions = model.predict(rnn_input_test)\n",
    "roc_auc_test = roc_auc_score(test_labels, test_predictions)\n",
    "print(f\"Test ROC AUC: {roc_auc_test}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T04:17:05.891361Z",
     "start_time": "2023-11-23T04:16:35.175226Z"
    }
   },
   "id": "de31f4d63b1bbdbf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we are left with a dilemma\n",
    "\n",
    "The error you encountered, ValueError: Found array with dim 3. None expected <= 2, is due to the roc_auc_score function expecting 1D array predictions and true labels, but the predictions made by your RNN model are 3D due to the return_sequences=True parameter in the SimpleRNN layer.\n",
    "\n",
    "\n",
    "To resolve this issue, we have two main options:\n",
    "\n",
    "Change return_sequences to False: This will make the RNN output predictions only for the last time step. It's the standard approach for many sequence classification tasks where the final prediction is based on the entire sequence.\n",
    "\n",
    "Aggregate the Predictions Across Time Steps: If our task requires predictions at each time step, that is return_sequences has to be True, then we will need to aggregate these predictions into a single prediction per sample before calculating ROC AUC.\n",
    "\n",
    "\n",
    "\n",
    "return_sequences=True\n",
    "Objective: The model predicts an output at each time step in the sequence. This is useful in scenarios where you need a prediction for each moment in time, not just a single prediction based on the entire sequence.\n",
    "\n",
    "Output: The output is a 3D tensor with dimensions (samples, time_steps, features). In a binary classification scenario, the third dimension usually represents the probability of belonging to one of the classes for each time step.\n",
    "\n",
    "Use Case Example: A common example is in natural language processing tasks like part-of-speech tagging, where you want to tag each word (time step) in a sentence (sequence). In a healthcare context, this might translate to making a diagnosis or prediction at each time interval based on the data up to that point.\n",
    "\n",
    "return_sequences=False\n",
    "Objective: The model makes a single prediction for the entire sequence. This is suitable for tasks where the outcome is dependent on the entire sequence, and you're interested in the final output at the last time step.\n",
    "\n",
    "Output: The output is a 2D tensor with dimensions (samples, features). For binary classification, this typically translates to a single probability score per sample.\n",
    "\n",
    "Use Case Example: An example could be sentiment analysis where the sentiment of the entire sentence (sequence) is determined. In healthcare, this might be used for predicting patient outcomes (like mortality or readmission) based on the entire sequence of their EHR data.\n",
    "\n",
    "Choosing the Right Approach for Your Task\n",
    "If your goal with the EHR dataset is to predict in-hospital mortality based on the entire sequence of recorded data (i.e., the prediction is about the final outcome at the end of the observed period), return_sequences=False is appropriate.\n",
    "\n",
    "If, however, you are interested in how the risk of mortality evolves at each time step (e.g., hour by hour prediction), then return_sequences=True would be the correct choice. This would provide a more granular view, potentially offering insights into how a patient's risk profile changes over time."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f68707b58624e09b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although keeping return_sequences = True might be the more interesting choice for me personally, our initial objective and the objective we used for all the other models aligns with changing to return_sequences=False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb4bb743e5cbb346"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "189/189 [==============================] - 5s 25ms/step\n",
      "40/40 [==============================] - 1s 16ms/step\n",
      "Epoch 1: roc_auc_train: 0.9331223660445515, roc_auc_val: 0.8586860670194003\n",
      "95/95 [==============================] - 18s 191ms/step - loss: 0.3125 - accuracy: 0.8767 - val_loss: 0.2577 - val_accuracy: 0.8936\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 5s 24ms/step\n",
      "40/40 [==============================] - 1s 16ms/step\n",
      "Epoch 2: roc_auc_train: 0.9853243527995185, roc_auc_val: 0.853407309425828\n",
      "95/95 [==============================] - 21s 227ms/step - loss: 0.1990 - accuracy: 0.9210 - val_loss: 0.2602 - val_accuracy: 0.8975\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 5s 23ms/step\n",
      "40/40 [==============================] - 1s 22ms/step\n",
      "Epoch 3: roc_auc_train: 0.9955614087898855, roc_auc_val: 0.8407615618263766\n",
      "95/95 [==============================] - 22s 230ms/step - loss: 0.1142 - accuracy: 0.9611 - val_loss: 0.3089 - val_accuracy: 0.8795\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 6s 28ms/step\n",
      "40/40 [==============================] - 1s 15ms/step\n",
      "Epoch 4: roc_auc_train: 0.9997145293999599, roc_auc_val: 0.8148331863609641\n",
      "95/95 [==============================] - 22s 232ms/step - loss: 0.0530 - accuracy: 0.9854 - val_loss: 0.3451 - val_accuracy: 0.8944\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 5s 23ms/step\n",
      "40/40 [==============================] - 1s 16ms/step\n",
      "Epoch 5: roc_auc_train: 0.9999954846478025, roc_auc_val: 0.7990765236135607\n",
      "95/95 [==============================] - 21s 223ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.4086 - val_accuracy: 0.8998\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 5s 23ms/step\n",
      "40/40 [==============================] - 1s 16ms/step\n",
      "Epoch 6: roc_auc_train: 0.9999989965884006, roc_auc_val: 0.7893947187928669\n",
      "95/95 [==============================] - 21s 222ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.4309 - val_accuracy: 0.8991\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 5s 23ms/step\n",
      "40/40 [==============================] - 1s 17ms/step\n",
      "Epoch 7: roc_auc_train: 0.9998256572345976, roc_auc_val: 0.8065721144424848\n",
      "95/95 [==============================] - 21s 224ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.4530 - val_accuracy: 0.8991\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 5s 25ms/step\n",
      "40/40 [==============================] - 1s 15ms/step\n",
      "Epoch 8: roc_auc_train: 0.9995379289584588, roc_auc_val: 0.7845568783068784\n",
      "95/95 [==============================] - 22s 236ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.4492 - val_accuracy: 0.8897\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 5s 24ms/step\n",
      "40/40 [==============================] - 1s 15ms/step\n",
      "Epoch 9: roc_auc_train: 1.0, roc_auc_val: 0.7944958847736627\n",
      "95/95 [==============================] - 20s 212ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.4962 - val_accuracy: 0.8951\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 5s 23ms/step\n",
      "40/40 [==============================] - 1s 23ms/step\n",
      "Epoch 10: roc_auc_train: 0.9999979931768012, roc_auc_val: 0.8007667058592984\n",
      "95/95 [==============================] - 21s 222ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.5106 - val_accuracy: 0.8826\n",
      "40/40 [==============================] - 1s 15ms/step - loss: 0.4542 - accuracy: 0.8884\n",
      "Test Loss: 0.4541586935520172, Test Accuracy: 0.8884493708610535\n",
      "40/40 [==============================] - 1s 22ms/step\n",
      "Test ROC AUC: 0.8207383017453689\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Custom callback to compute ROC AUC after each epoch\n",
    "class RocAucCallback(Callback):\n",
    "    def __init__(self, training_data, validation_data):\n",
    "        self.x_train, self.y_train = training_data\n",
    "        self.x_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_train_pred = self.model.predict(self.x_train)\n",
    "        y_val_pred = self.model.predict(self.x_val)\n",
    "        roc_auc_train = roc_auc_score(self.y_train, y_train_pred)\n",
    "        roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
    "        print(f'Epoch {epoch+1}: roc_auc_train: {roc_auc_train}, roc_auc_val: {roc_auc_val}')\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, return_sequences=False, input_shape=(48, 7403)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Instantiate the RocAucCallback\n",
    "rocauc_callback = RocAucCallback(training_data=(rnn_input_train, train_labels),\n",
    "                                 validation_data=(rnn_input_val, val_labels))\n",
    "\n",
    "# Train the model with validation data and the custom callback\n",
    "model.fit(rnn_input_train, train_labels, epochs=10, batch_size=64, \n",
    "          validation_data=(rnn_input_val, val_labels), callbacks=[rocauc_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(rnn_input_test, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate and print ROC AUC for the test set\n",
    "test_predictions = model.predict(rnn_input_test)\n",
    "roc_auc_test = roc_auc_score(test_labels, test_predictions)\n",
    "print(f\"Test ROC AUC: {roc_auc_test}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T04:28:39.534532Z",
     "start_time": "2023-11-23T04:25:03.426769Z"
    }
   },
   "id": "407232c13ae76cb5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training and Validation Performance\n",
    "Accuracy and Loss over Epochs:\n",
    "\n",
    "Training Accuracy increases significantly over epochs, reaching near-perfect levels. This suggests that the model is learning to classify the training data very effectively.\n",
    "Validation Accuracy also increases but plateaus and remains lower than the training accuracy. This indicates that while the model is learning generalizable patterns, there might be some overfitting to the training data.\n",
    "Training Loss decreases rapidly, which is expected as the model learns.\n",
    "Validation Loss initially decreases but then starts to increase, which is a classic sign of overfitting.\n",
    "ROC AUC Scores:\n",
    "\n",
    "Training ROC AUC is very high, close to 1.0, which suggests excellent performance on the training set.\n",
    "Validation ROC AUC is lower than the training ROC AUC and shows some fluctuation. While it's still a good score, the gap between training and validation indicates the model may be overfitting.\n",
    "Test Performance\n",
    "Test Accuracy: The accuracy on the test set is 0.8884, which is good but lower than the training accuracy, supporting the indication of overfitting.\n",
    "Test ROC AUC: A score of 0.8207 is quite strong, indicating that the model has good discriminative ability on the test data.\n",
    "Interpretation and Next Steps\n",
    "Overfitting: The model seems to be overfitting the training data. This is evident from the high training accuracy and ROC AUC, and the growing gap between training and validation loss. Regularization techniques, dropout, or more sophisticated RNN layers like LSTM or GRU could help mitigate this.\n",
    "\n",
    "Model Complexity: You might need to adjust the model's complexity. If it's too complex for the data, simplifying the model could help improve generalizability.\n",
    "\n",
    "Hyperparameter Tuning: Experimenting with different learning rates, number of epochs, batch sizes, and other hyperparameters could yield better performance.\n",
    "\n",
    "Data Representation: Consider if the way you're feeding data into the model is optimal. Since RNNs are sensitive to the sequence length and feature representation, adjustments here might be beneficial.\n",
    "\n",
    "Further Evaluation: Dive deeper into the types of errors the model is making. Confusion matrices, precision-recall curves, and analyzing misclassified examples can provide more insights.\n",
    "\n",
    "Remember, while accuracy and ROC AUC are important metrics, they don't always tell the whole story, especially in imbalanced datasets common in healthcare contexts. Balancing sensitivity and specificity is crucial, and focusing on clinical relevance is key."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7d4b4f616badcd0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Addressing overfitting in an RNN model, especially when dealing with a complex and high-dimensional dataset involves a combination of strategies. Here are some approaches to consider:\n",
    "\n",
    "3. Regularization\n",
    "Add Dropout: Dropout layers randomly set a fraction of input units to 0 at each update during training, which helps prevent overfitting. You can add them between RNN layers or Dense layers.\n",
    "L1/L2 Regularization: Apply L1 or L2 regularization to the weights of the network layers. This can be done through the kernel_regularizer parameter in the layers. This did not yield great metrics when applied with linear regression so did not apply. \n",
    "2. Model Complexity\n",
    "Reduce Model Size: Simplify your model by reducing the number of neurons in each layer or reducing the number of layers. A smaller model is less prone to overfitting. I wanted to try this strategy but first wanted to use LSTM or GRU layers to see how the metrics change if we actually increase the complexity given that they are long-term dependencies. \n",
    "3. Early Stopping\n",
    "Implement early stopping during training. This stops training when the model performance stops improving on a validation dataset.\n",
    "4. Advanced RNN Layers\n",
    "Use LSTM or GRU Layers: These layers are more complex than simple RNN layers and are better at capturing long-term dependencies without overfitting.\n",
    "7. Hyperparameter Tuning\n",
    "Experiment with different learning rates, batch sizes, or other hyperparameters.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91ddcd91315471a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Changes Implemented to the RNN Model to Address Overfitting**\n",
    "\n",
    "GRU Layer: You've replaced the SimpleRNN layer with a GRU layer, which is generally better at capturing long-term dependencies in the data.\n",
    "\n",
    "Dropout: The addition of a Dropout layer (with a dropout rate of 0.2) will help in preventing overfitting by randomly setting a fraction of the input units to 0 at each update during training.\n",
    "\n",
    "Early Stopping: You've included an EarlyStopping callback, which will stop the training process if the model's performance on the validation set doesn't improve for 3 consecutive epochs (patience=3). This prevents overfitting by not allowing the model to train excessively.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c6f2d0234457ba9"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "189/189 [==============================] - 5s 26ms/step\n",
      "40/40 [==============================] - 1s 21ms/step\n",
      "Epoch 1: roc_auc_train: 0.9233619305639174, roc_auc_val: 0.8726055751518715\n",
      "95/95 [==============================] - 28s 284ms/step - loss: 0.3141 - accuracy: 0.8756 - val_loss: 0.2442 - val_accuracy: 0.9085\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 5s 27ms/step\n",
      "40/40 [==============================] - 1s 20ms/step\n",
      "Epoch 2: roc_auc_train: 0.9708604254465181, roc_auc_val: 0.8746448167744464\n",
      "95/95 [==============================] - 26s 272ms/step - loss: 0.2088 - accuracy: 0.9160 - val_loss: 0.2474 - val_accuracy: 0.9006\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 5s 27ms/step\n",
      "40/40 [==============================] - 1s 21ms/step\n",
      "Epoch 3: roc_auc_train: 0.9865467589805338, roc_auc_val: 0.8688577797374093\n",
      "95/95 [==============================] - 26s 276ms/step - loss: 0.1539 - accuracy: 0.9422 - val_loss: 0.2668 - val_accuracy: 0.9030\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 6s 28ms/step\n",
      "40/40 [==============================] - 1s 22ms/step\n",
      "Epoch 4: roc_auc_train: 0.994092915914108, roc_auc_val: 0.8531501077797375\n",
      "95/95 [==============================] - 26s 279ms/step - loss: 0.1023 - accuracy: 0.9604 - val_loss: 0.3319 - val_accuracy: 0.8787\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.3181 - accuracy: 0.8750\n",
      "Test Loss: 0.3180674910545349, Test Accuracy: 0.875\n",
      "40/40 [==============================] - 1s 20ms/step\n",
      "Test ROC AUC: 0.8593934040047115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dropout, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Custom callback to compute ROC AUC after each epoch\n",
    "class RocAucCallback(Callback):\n",
    "    def __init__(self, training_data, validation_data):\n",
    "        self.x_train, self.y_train = training_data\n",
    "        self.x_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_train_pred = self.model.predict(self.x_train)\n",
    "        y_val_pred = self.model.predict(self.x_val)\n",
    "        roc_auc_train = roc_auc_score(self.y_train, y_train_pred)\n",
    "        roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
    "        print(f'Epoch {epoch+1}: roc_auc_train: {roc_auc_train}, roc_auc_val: {roc_auc_val}')\n",
    "\n",
    "\n",
    "\n",
    "# Define the RNN model with Dropout and GRU\n",
    "model = Sequential()\n",
    "model.add(GRU(50, return_sequences=False, input_shape=(48, 7403)))\n",
    "model.add(Dropout(0.2))  # Dropout layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model with validation data and callbacks for early stopping\n",
    "model.fit(rnn_input_train, train_labels, epochs=10, batch_size=64, \n",
    "          validation_data=(rnn_input_val, val_labels), callbacks=[rocauc_callback, early_stopping])\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(rnn_input_test, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate and print ROC AUC for the test set\n",
    "test_predictions = model.predict(rnn_input_test)\n",
    "roc_auc_test = roc_auc_score(test_labels, test_predictions)\n",
    "print(f\"Test ROC AUC: {roc_auc_test}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:52:46.348085Z",
     "start_time": "2023-11-23T13:50:49.604653Z"
    }
   },
   "id": "285e431e5e0091"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training and Validation Performance Over Epochs\n",
    "Accuracy and Loss:\n",
    "\n",
    "Training Accuracy increases over epochs, indicating the model is learning to classify the training data effectively.\n",
    "Validation Accuracy also increases initially but doesn't reach the same level as training accuracy and slightly decreases in the later epochs. This suggests some overfitting to the training data.\n",
    "Training Loss decreases consistently, which is expected as the model learns.\n",
    "Validation Loss initially decreases but then starts increasing, a sign of overfitting. The model performs well initially but begins to lose generalizability in later epochs.\n",
    "ROC AUC Scores:\n",
    "\n",
    "Training ROC AUC improves steadily, reaching a very high score, which suggests excellent performance on the training set.\n",
    "Validation ROC AUC is relatively high initially but begins to decline. This discrepancy between training and validation ROC AUC is another indicator of overfitting.\n",
    "Test Performance\n",
    "Test Accuracy: The accuracy on the test set is 0.875, which is fairly good but noticeably lower than the peak training accuracy. This gap further supports the overfitting indication.\n",
    "Test ROC AUC: A score of 0.8594 is quite good and indicates that the model has a strong ability to distinguish between the classes. However, this score is still lower than what the model achieved on the training set.\n",
    "Overall Interpretation\n",
    "The model learns to fit the training data well, but it starts to overfit as indicated by the increasing validation loss and the decreasing validation ROC AUC in later epochs.\n",
    "The test performance, while good, doesn't match the model's performance on the training set, which is consistent with the overfitting pattern observed during training.\n",
    "The ROC AUC scores are a highlight, indicating that the model has a good discriminative ability, but there's still room for improvement, especially in terms of generalizability."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d042d4aec3ad05c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Changes to RNN to address the persistent overfitting**\n",
    "Hyperparameter Tuning: Adjusting the architecture by using LSTM layers instead could yield better results.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22a67ab76e2e054f"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "189/189 [==============================] - 6s 28ms/step\n",
      "40/40 [==============================] - 1s 22ms/step\n",
      "Epoch 1: roc_auc_train: 0.926501856311459, roc_auc_val: 0.8825262100725063\n",
      "95/95 [==============================] - 29s 294ms/step - loss: 0.3058 - accuracy: 0.8795 - val_loss: 0.2438 - val_accuracy: 0.9077\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 6s 30ms/step\n",
      "40/40 [==============================] - 1s 23ms/step\n",
      "Epoch 2: roc_auc_train: 0.9663689042745334, roc_auc_val: 0.8747427983539094\n",
      "95/95 [==============================] - 28s 292ms/step - loss: 0.2157 - accuracy: 0.9155 - val_loss: 0.2472 - val_accuracy: 0.9069\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 6s 29ms/step\n",
      "40/40 [==============================] - 1s 21ms/step\n",
      "Epoch 3: roc_auc_train: 0.9822353501906481, roc_auc_val: 0.8627155594748187\n",
      "95/95 [==============================] - 28s 293ms/step - loss: 0.1624 - accuracy: 0.9345 - val_loss: 0.2688 - val_accuracy: 0.8983\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 5s 27ms/step\n",
      "40/40 [==============================] - 1s 21ms/step\n",
      "Epoch 4: roc_auc_train: 0.9945459562512543, roc_auc_val: 0.8474794238683128\n",
      "95/95 [==============================] - 27s 283ms/step - loss: 0.1128 - accuracy: 0.9581 - val_loss: 0.3348 - val_accuracy: 0.8998\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.2985 - accuracy: 0.9043\n",
      "Test Loss: 0.29847025871276855, Test Accuracy: 0.9042721390724182\n",
      "40/40 [==============================] - 1s 20ms/step\n",
      "Test ROC AUC: 0.8616353463968303\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "# Custom callback to compute ROC AUC after each epoch\n",
    "class RocAucCallback(Callback):\n",
    "    def __init__(self, training_data, validation_data):\n",
    "        self.x_train, self.y_train = training_data\n",
    "        self.x_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_train_pred = self.model.predict(self.x_train)\n",
    "        y_val_pred = self.model.predict(self.x_val)\n",
    "        roc_auc_train = roc_auc_score(self.y_train, y_train_pred)\n",
    "        roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
    "        print(f'Epoch {epoch+1}: roc_auc_train: {roc_auc_train}, roc_auc_val: {roc_auc_val}')\n",
    "\n",
    "# Define the RNN model with an LSTM layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=False, input_shape=(48, 7403)))\n",
    "model.add(Dropout(0.2))  # Dropout layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model with validation data and callbacks for early stopping\n",
    "model.fit(rnn_input_train, train_labels, epochs=10, batch_size=64, \n",
    "          validation_data=(rnn_input_val, val_labels), callbacks=[rocauc_callback, early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(rnn_input_test, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate and print ROC AUC for the test set\n",
    "test_predictions = model.predict(rnn_input_test)\n",
    "roc_auc_test = roc_auc_score(test_labels, test_predictions)\n",
    "print(f\"Test ROC AUC: {roc_auc_test}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:05:08.226306Z",
     "start_time": "2023-11-23T14:03:10.931437Z"
    }
   },
   "id": "16471de41eacbe0b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Adapting Existing Top Performing Models to my Preprocessed Data**\n",
    "\n",
    "There are top performing models out there with the hopes of being used as benchmarks. However, because the FIDDLE preprocessing is a more robust preprocessing technique than employed for the previous benchmarks, there are no models built on this specific preprocessed dataset. Hence, the next two models use the architecture from existing benchmark models and adapted to the current dataset and preprocessing functions to ensure good scientific practice.\n",
    "\n",
    "\n",
    "First Benchmark Model (LSTM):\n",
    "Source: https://github.com/YerevaNN/mimic3-benchmarks\n",
    "\n",
    "The model below has the same architecture to the model we built from scratch, indicating that we did quite well in reaching the standard benchmark for in-hospital mortality from scratch using a more robust preprocessing technique. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9766e666d8029b8b"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "189/189 [==============================] - 6s 28ms/step\n",
      "40/40 [==============================] - 1s 21ms/step\n",
      "Epoch 1: roc_auc_train: 0.9234958860124423, roc_auc_val: 0.8815525181265923\n",
      "95/95 [==============================] - 29s 295ms/step - loss: 0.3077 - accuracy: 0.8807 - val_loss: 0.2408 - val_accuracy: 0.9069\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 6s 28ms/step\n",
      "40/40 [==============================] - 1s 22ms/step\n",
      "Epoch 2: roc_auc_train: 0.9710412903873169, roc_auc_val: 0.8793969233784048\n",
      "95/95 [==============================] - 27s 283ms/step - loss: 0.2099 - accuracy: 0.9150 - val_loss: 0.2549 - val_accuracy: 0.9100\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 6s 28ms/step\n",
      "40/40 [==============================] - 1s 21ms/step\n",
      "Epoch 3: roc_auc_train: 0.9886115291992775, roc_auc_val: 0.8761880266509896\n",
      "95/95 [==============================] - 27s 285ms/step - loss: 0.1537 - accuracy: 0.9413 - val_loss: 0.2624 - val_accuracy: 0.9038\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 6s 28ms/step\n",
      "40/40 [==============================] - 1s 22ms/step\n",
      "Epoch 4: roc_auc_train: 0.9970226269315673, roc_auc_val: 0.8670389966686263\n",
      "95/95 [==============================] - 28s 299ms/step - loss: 0.0985 - accuracy: 0.9655 - val_loss: 0.3141 - val_accuracy: 0.8975\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.2798 - accuracy: 0.9051\n",
      "Test Loss: 0.2797945737838745, Test Accuracy: 0.905063271522522\n",
      "40/40 [==============================] - 1s 21ms/step\n",
      "Test ROC AUC: 0.8761711639361817\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "# Custom callback to compute ROC AUC after each epoch\n",
    "class RocAucCallback(Callback):\n",
    "    def __init__(self, training_data, validation_data):\n",
    "        self.x_train, self.y_train = training_data\n",
    "        self.x_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_train_pred = self.model.predict(self.x_train)\n",
    "        y_val_pred = self.model.predict(self.x_val)\n",
    "        roc_auc_train = roc_auc_score(self.y_train, y_train_pred)\n",
    "        roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
    "        print(f'Epoch {epoch+1}: roc_auc_train: {roc_auc_train}, roc_auc_val: {roc_auc_val}')\n",
    "\n",
    "# Define the RNN model with an LSTM layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=False, input_shape=(48, 7403)))  # Adjust the input shape as needed\n",
    "model.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model with validation data and callbacks for early stopping\n",
    "model.fit(rnn_input_train, train_labels, epochs=10, batch_size=64, \n",
    "          validation_data=(rnn_input_val, val_labels), callbacks=[rocauc_callback, early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(rnn_input_test, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate and print ROC AUC for the test set\n",
    "test_predictions = model.predict(rnn_input_test)\n",
    "roc_auc_test = roc_auc_score(test_labels, test_predictions)\n",
    "print(f\"Test ROC AUC: {roc_auc_test}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:27:29.598731Z",
     "start_time": "2023-11-23T14:25:27.174287Z"
    }
   },
   "id": "4cbf25defa302d97"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Second Benchmark Test**\n",
    "Source: https://paperswithcode.com/paper/early-hospital-mortality-prediction-using\n",
    "\n",
    "Below is a benchmark that supposedly yields the best results; however, there is no difference in results or architecture in the benchmark-adapted random forest (thats supposed to beat all models for in hospital mortality) and the random forest we created from scratch. Both have poor performance due to a low AUROC score as can be observed below. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6fb3153d7421fa4"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8955696202531646\n",
      "ROC AUC: 0.5133847306992183\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      1132\n",
      "           1       0.50      0.03      0.06       132\n",
      "\n",
      "    accuracy                           0.90      1264\n",
      "   macro avg       0.70      0.51      0.50      1264\n",
      "weighted avg       0.86      0.90      0.85      1264\n",
      "\n",
      "Top Feature rankings:\n",
      "1. Feature: 226104_value_Unresponsive_time46, Importance: 0.0017349550073114859\n",
      "2. Feature: 225154_InputRoute: Continuous Med_value_1.0_time46, Importance: 0.0013277409871644932\n",
      "3. Feature: 225792_value_1.0_time46, Importance: 0.000993736674619391\n",
      "4. Feature: 225154_InputRoute: Continuous Med_value_1.0_time47, Importance: 0.0009186840100308196\n",
      "5. Feature: 225792_value_1.0_time34, Importance: 0.0008215305539938766\n",
      "6. Feature: 221906_value_1.0_time37, Importance: 0.0008183066326337454\n",
      "7. Feature: 223904_value_Absent_time30, Importance: 0.000745496294177183\n",
      "8. Feature: 221906_Rate_value_(0.0262, 9.356]_time42, Importance: 0.0007307279700927923\n",
      "9. Feature: 220739_value_None_time46, Importance: 0.0007251080206447534\n",
      "10. Feature: 225792_value_1.0_time37, Importance: 0.0007247672172312946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "# Assuming your training data is a combination of time-dependent and time-independent features\n",
    "random_forest_model.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the test data\n",
    "test_predictions = random_forest_model.predict(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "roc_auc = roc_auc_score(test_labels, test_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Feature Importance Analysis\n",
    "importances = random_forest_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Assuming 'total_feature_names' is a list of your feature names\n",
    "print(\"Top Feature rankings:\")\n",
    "for i in range(10):  # Adjust the range if you want more or fewer features\n",
    "    print(f\"{i + 1}. Feature: {total_feature_names[indices[i]]}, Importance: {importances[indices[i]]}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:37:19.469084Z",
     "start_time": "2023-11-23T14:35:45.207085Z"
    }
   },
   "id": "aa3c1ca3caa79de6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d905d027c610e0f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
